import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from slider import add_sidebar_links

add_sidebar_links()

# Titre principal
st.title("üìà Analyse des Vendeurs et Mod√©lisation")

# ============================
# Section 1 : Visualisation des Donn√©es
# ============================
st.header("üìä Visualisation des Donn√©es")

# Charger les donn√©es (remplacez par votre propre dataset)
sellers = pd.read_csv("data/seller.csv")  # Assurez-vous d'avoir un fichier CSV appropri√©

# Cr√©er des graphiques
st.subheader("üîç Scatter Plots des Vendeurs")
fig, axes = plt.subplots(2, 2, figsize=(12, 9))

# Graphique 1 : Total Products Sold vs Total Products Listed
axes[0, 0].scatter(sellers.totalproductssold, sellers.totalproductslisted, alpha=0.6, color='blue')
axes[0, 0].set_xlabel('Total Products Sold')
axes[0, 0].set_ylabel('Total Products Listed')
axes[0, 0].set_title('Total Products Sold vs Total Products Listed')

# Graphique 2 : Total Products Sold vs Total Products Bought
axes[0, 1].scatter(sellers.totalproductssold, sellers.totalbought, alpha=0.6, color='green')
axes[0, 1].set_xlabel('Total Products Sold')
axes[0, 1].set_ylabel('Total Products Bought')
axes[0, 1].set_title('Total Products Sold vs Total Products Bought')

# Graphique 3 : Total Products Sold vs Total Products Wished
axes[1, 0].scatter(sellers.totalproductssold, sellers.totalwished, alpha=0.6, color='orange')
axes[1, 0].set_xlabel('Total Products Sold')
axes[1, 0].set_ylabel('Total Products Wished')
axes[1, 0].set_title('Total Products Sold vs Total Products Wished')

# Graphique 4 : Total Products Sold vs Total Products Liked
axes[1, 1].scatter(sellers.totalproductssold, sellers.totalproductsliked, alpha=0.6, color='red')
axes[1, 1].set_xlabel('Total Products Sold')
axes[1, 1].set_ylabel('Total Products Liked')
axes[1, 1].set_title('Total Products Sold vs Total Products Liked')

plt.tight_layout()
st.pyplot(fig)

# Explication des graphiques
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üìà Ces scatter plots montrent une corr√©lation positive entre le nombre total de produits vendus et les autres variables (list√©s, achet√©s, souhait√©s, aim√©s). 
    Quelques points extr√™mes indiquent des vendeurs tr√®s actifs qui influencent fortement les tendances. 
    La densit√© √©lev√©e pr√®s de l'origine sugg√®re que la majorit√© des vendeurs ont une activit√© limit√©e. 
    Plus un vendeur vend, plus ses produits sont list√©s, achet√©s, souhait√©s et aim√©s.
</p>
""", unsafe_allow_html=True)

# ============================
# Section 2 : Standardisation et ACP
# ============================
st.header("üîß Standardisation et Analyse en Composantes Principales (ACP)")

# Standardisation des variables
features = ['totalproductslisted', 'totalbought', 'totalwished', 'totalproductsliked']
target = 'totalproductssold'

X = sellers[features]
y = sellers[target]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ACP
pca_temp = PCA().fit(X_scaled)
cumulative_variance = pca_temp.explained_variance_ratio_.cumsum()
st.write(f"**Variance Cumul√©e Expliqu√©e :** {cumulative_variance}")

n_components = 2
pca = PCA(n_components=n_components)
X_pca = pca.fit_transform(X_scaled)

st.write(f"**Variance Expliqu√©e par Composant :** {pca.explained_variance_ratio_}")

st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üéØ Les deux premiers composants principaux expliquent 99.7% de la variance cumul√©e des donn√©es, ce qui signifie qu'ils capturent presque toute l'information pertinente. 
    Le premier composant seul explique 98.5% de la variance, tandis que le deuxi√®me n'ajoute que 1.1%. 
    Cela sugg√®re que la r√©duction √† deux dimensions est tr√®s efficace pour repr√©senter les donn√©es.
</p>
""", unsafe_allow_html=True)

# ============================
# Section 3 : Mod√©lisation
# ============================
st.header("ü§ñ Mod√©lisation avec R√©gression Lin√©aire")

# Division des donn√©es
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# Entra√Ænement du mod√®le
lr = LinearRegression()
lr.fit(X_train, y_train)

# Pr√©dictions
y_train_pred = lr.predict(X_train)
y_test_pred = lr.predict(X_test)

# M√©triques d'√©valuation
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

st.subheader("üìä Performance du Mod√®le")
st.write(f"**MSE (Ensemble d'Entra√Ænement) :** {train_mse}")
st.write(f"**MSE (Ensemble de Test) :** {test_mse}")
st.write(f"**R¬≤ (Ensemble d'Entra√Ænement) :** {train_r2}")
st.write(f"**R¬≤ (Ensemble de Test) :** {test_r2}")

# Validation crois√©e
cv_scores = cross_val_score(lr, X_pca, y, cv=5, scoring='neg_mean_squared_error')
st.write(f"**MSE Moyen (Validation Crois√©e) :** {-cv_scores.mean():.2f}")

st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üö® Le MSE moyen obtenu par validation crois√©e est de 134 442,33, ce qui est nettement plus √©lev√© que le MSE sur le test. 
    Cela pourrait indiquer que le mod√®le est moins performant sur certains sous-ensembles de donn√©es, ce qui renforce l'hypoth√®se d'un possible surapprentissage.
</p>
""", unsafe_allow_html=True)

# Graphique des valeurs r√©elles vs pr√©dites
st.subheader("üìà Valeurs R√©elles vs Pr√©dites")
fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(y_test, y_test_pred, alpha=0.7, color='purple')
ax.set_xlabel("Valeurs R√©elles")
ax.set_ylabel("Valeurs Pr√©dites")
ax.set_title("Valeurs R√©elles vs Pr√©dites")
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
st.pyplot(fig)

st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    ‚úÖ Presque tous les points suivent cette ligne, le mod√®le fait des pr√©dictions tr√®s pr√©cises. 
    Cela sugg√®re une forte corr√©lation entre les valeurs r√©elles et pr√©dites.
</p>
""", unsafe_allow_html=True)

# ============================
# Section 4 : Pr√©diction avec de Nouvelles Donn√©es
# ============================
st.header("üîÆ Pr√©diction avec de Nouvelles Donn√©es")

# Exemple de nouvelles donn√©es
new_data = {
    'totalproductslisted': [150],   # Exemple de valeur pour le total des produits r√©pertori√©s
    'totalbought': [75],            # Exemple de valeur pour le total des produits achet√©s
    'totalwished': [50],            # Exemple de valeur pour le total des produits souhait√©s
    'totalproductsliked': [100]     # Exemple de valeur pour le total des produits aim√©s
}

# Convertir les donn√©es en DataFrame
st.write("**Nouvelles Donn√©es pour Pr√©diction :**")
new_df = pd.DataFrame(new_data)
st.write(new_df)

# Conversion en DataFrame
new_df = pd.DataFrame(new_data)

# Standardisation et ACP
new_scaled = scaler.transform(new_df)
new_pca = pca.transform(new_scaled)

# Pr√©diction
predicted_products_sold = lr.predict(new_pca)
st.write(f"**Total des Produits Vendus Pr√©dits :** {predicted_products_sold[0]:.2f}")