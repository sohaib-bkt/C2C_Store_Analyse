import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, GridSearchCV
from slider import add_sidebar_links

add_sidebar_links()

# Titre principal
st.title("üìä R√©gression Ridge et Lasso")

# ============================
# Section 1 : Introduction
# ============================
st.header("üìö Introduction")
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üõ†Ô∏è Les mod√®les Ridge et Lasso sont des techniques de r√©gularisation utilis√©es pour am√©liorer les performances des mod√®les de r√©gression lin√©aire, 
    en particulier lorsque les donn√©es pr√©sentent des probl√®mes de multicolin√©arit√© (variables explicatives fortement corr√©l√©es) ou de surapprentissage (overfitting).
</p>
""", unsafe_allow_html=True)

# ============================
# Section 2 : Visualisation des Donn√©es
# ============================
st.header("üìä Visualisation des Donn√©es")

# Charger les donn√©es (remplacez par votre propre dataset)
sellers = pd.read_csv("data/seller.csv")  # Assurez-vous d'avoir un fichier CSV appropri√©

# Cr√©er des graphiques
st.subheader("üîç Scatter Plots des Vendeurs")
fig, axes = plt.subplots(2, 2, figsize=(12, 9))

# Graphique 1 : Total Products Sold vs Total Products Listed
axes[0, 0].scatter(sellers.totalproductssold, sellers.totalproductslisted, alpha=0.6, color='blue')
axes[0, 0].set_xlabel('Total Products Sold')
axes[0, 0].set_ylabel('Total Products Listed')
axes[0, 0].set_title('Total Products Sold vs Total Products Listed')

# Graphique 2 : Total Products Sold vs Total Products Bought
axes[0, 1].scatter(sellers.totalproductssold, sellers.totalbought, alpha=0.6, color='green')
axes[0, 1].set_xlabel('Total Products Sold')
axes[0, 1].set_ylabel('Total Products Bought')
axes[0, 1].set_title('Total Products Sold vs Total Products Bought')

# Graphique 3 : Total Products Sold vs Total Products Wished
axes[1, 0].scatter(sellers.totalproductssold, sellers.totalwished, alpha=0.6, color='orange')
axes[1, 0].set_xlabel('Total Products Sold')
axes[1, 0].set_ylabel('Total Products Wished')
axes[1, 0].set_title('Total Products Sold vs Total Products Wished')

# Graphique 4 : Total Products Sold vs Total Products Liked
axes[1, 1].scatter(sellers.totalproductssold, sellers.totalproductsliked, alpha=0.6, color='red')
axes[1, 1].set_xlabel('Total Products Sold')
axes[1, 1].set_ylabel('Total Products Liked')
axes[1, 1].set_title('Total Products Sold vs Total Products Liked')

plt.tight_layout()
st.pyplot(fig)

# ============================
# Section 3 : Pr√©paration des Donn√©es
# ============================
st.header("üîß Pr√©paration des Donn√©es")

# D√©finir les fonctionnalit√©s et la cible
features = ['totalproductslisted', 'totalbought', 'totalwished', 'totalproductsliked']
target = 'totalproductssold'

X = sellers[features]
y = sellers[target]

# Standardisation des donn√©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Division des donn√©es
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ============================
# Section 4 : R√©gression Ridge
# ============================
st.header("üèîÔ∏è R√©gression Ridge")

# Initialisation du mod√®le Ridge
ridge = Ridge()

# Grille d'hyperparam√®tres pour Ridge
param_grid_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}

# Recherche des meilleurs param√®tres
grid_search_ridge = GridSearchCV(ridge, param_grid_ridge, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)
grid_search_ridge.fit(X_train, y_train)

# Meilleurs param√®tres pour Ridge
st.write(f"**Meilleurs param√®tres pour Ridge :** {grid_search_ridge.best_params_}")

# Mod√®le Ridge optimis√©
best_ridge = grid_search_ridge.best_estimator_

# Pr√©dictions et √©valuation
y_train_pred_ridge = best_ridge.predict(X_train)
y_test_pred_ridge = best_ridge.predict(X_test)

train_mse_ridge = mean_squared_error(y_train, y_train_pred_ridge)
test_mse_ridge = mean_squared_error(y_test, y_test_pred_ridge)
train_r2_ridge = r2_score(y_train, y_train_pred_ridge)
test_r2_ridge = r2_score(y_test, y_test_pred_ridge)

st.subheader("üìä Performance du Mod√®le Ridge")
st.write(f"**MSE (Ensemble d'Entra√Ænement) :** {train_mse_ridge:.2f}")
st.write(f"**MSE (Ensemble de Test) :** {test_mse_ridge:.2f}")
st.write(f"**R¬≤ (Ensemble d'Entra√Ænement) :** {train_r2_ridge:.4f}")
st.write(f"**R¬≤ (Ensemble de Test) :** {test_r2_ridge:.4f}")

# ============================
# Section 5 : R√©gression Lasso
# ============================
st.header("üéØ R√©gression Lasso")

# Initialisation du mod√®le Lasso
lasso = Lasso()

# Grille d'hyperparam√®tres pour Lasso
param_grid_lasso = {'alpha': [0.01, 0.1, 1, 10, 100]}

# Recherche des meilleurs param√®tres
grid_search_lasso = GridSearchCV(lasso, param_grid_lasso, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)
grid_search_lasso.fit(X_train, y_train)

# Meilleurs param√®tres pour Lasso
st.write(f"**Meilleurs param√®tres pour Lasso :** {grid_search_lasso.best_params_}")

# Mod√®le Lasso optimis√©
best_lasso = grid_search_lasso.best_estimator_

# Pr√©dictions et √©valuation
y_train_pred_lasso = best_lasso.predict(X_train)
y_test_pred_lasso = best_lasso.predict(X_test)

train_mse_lasso = mean_squared_error(y_train, y_train_pred_lasso)
test_mse_lasso = mean_squared_error(y_test, y_test_pred_lasso)
train_r2_lasso = r2_score(y_train, y_train_pred_lasso)
test_r2_lasso = r2_score(y_test, y_test_pred_lasso)

st.subheader("üìä Performance du Mod√®le Lasso")
st.write(f"**MSE (Ensemble d'Entra√Ænement) :** {train_mse_lasso:.2f}")
st.write(f"**MSE (Ensemble de Test) :** {test_mse_lasso:.2f}")
st.write(f"**R¬≤ (Ensemble d'Entra√Ænement) :** {train_r2_lasso:.4f}")
st.write(f"**R¬≤ (Ensemble de Test) :** {test_r2_lasso:.4f}")

# ============================
# Section 6 : Visualisation des Coefficients
# ============================
st.header("üìâ Visualisation des Coefficients")

# Cr√©er des graphiques
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Coefficients Ridge
axes[0].barh(features, best_ridge.coef_)
axes[0].set_title("Coefficients Ridge")
axes[0].set_xlabel("Valeur du coefficient")

# Coefficients Lasso
axes[1].barh(features, best_lasso.coef_)
axes[1].set_title("Coefficients Lasso")
axes[1].set_xlabel("Valeur du coefficient")

plt.tight_layout()
st.pyplot(fig)

# ============================
# Section 7 : Comparaison des Mod√®les
# ============================
st.header("üÜö Comparaison des Mod√®les")
st.write(f"**Ridge Test MSE :** {test_mse_ridge:.2f} | **Lasso Test MSE :** {test_mse_lasso:.2f}")
st.write(f"**Ridge Test R¬≤ :** {test_r2_ridge:.4f} | **Lasso Test R¬≤ :** {test_r2_lasso:.4f}")

st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üèÜ Les mod√®les Ridge et Lasso montrent des performances exceptionnelles les donn√©es, avec une g√©n√©ralisation presque parfaite. 
    Ridge est l√©g√®rement meilleur en termes de MSE et R¬≤, mais Lasso offre une simplification du mod√®le en s√©lectionnant les variables les plus importantes. 
    Choisissez Ridge si la performance est prioritaire, ou Lasso si la simplicit√© et l'interpr√©tabilit√© sont plus importantes.
</p>
""", unsafe_allow_html=True)



# D√©finir les fonctionnalit√©s et la cible
features = ['totalproductslisted', 'totalbought', 'totalwished', 'totalproductsliked']
target = 'totalproductssold'

X = sellers[features]
y = sellers[target]

# Standardisation des donn√©es
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Division des donn√©es
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ============================
# Section 3 : R√©gression Lasso
# ============================
st.header("üéØ R√©gression Lasso")

# Initialisation et entra√Ænement du mod√®le Lasso
lasso = Lasso(alpha=0.1)  # Vous pouvez ajuster alpha selon vos besoins
lasso.fit(X_train, y_train)

# Pr√©dictions avec Lasso
lasso_pred = lasso.predict(X_test)

# Graphique des valeurs r√©elles vs pr√©dites
st.subheader("üìà Valeurs R√©elles vs Pr√©dites (Lasso)")
fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(y_test, lasso_pred, alpha=0.7, color='purple', label='Pr√©dictions Lasso')
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ligne de R√©f√©rence')
ax.set_xlabel("Valeurs R√©elles")
ax.set_ylabel("Valeurs Pr√©dites")
ax.set_title("Valeurs R√©elles vs Pr√©dites (Lasso)")
ax.legend()
st.pyplot(fig)

# Interpr√©tation
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üìä Le graphique montre une forte corr√©lation entre les valeurs r√©elles et pr√©dites par le mod√®le Lasso. 
    La plupart des points sont proches de la ligne de r√©f√©rence, ce qui indique que le mod√®le fait des pr√©dictions pr√©cises.
</p>
""", unsafe_allow_html=True)

# ============================
# Section 4 : R√©gression Ridge
# ============================
st.header("üèîÔ∏è R√©gression Ridge")

# Initialisation et entra√Ænement du mod√®le Ridge
ridge = Ridge(alpha=1.0)  # Vous pouvez ajuster alpha selon vos besoins
ridge.fit(X_train, y_train)

# Pr√©dictions avec Ridge
ridge_pred = ridge.predict(X_test)

# Graphique des valeurs r√©elles vs pr√©dites
st.subheader("üìà Valeurs R√©elles vs Pr√©dites (Ridge)")
fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(y_test, ridge_pred, alpha=0.7, color='blue', label='Pr√©dictions Ridge')
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Ligne de R√©f√©rence')
ax.set_xlabel("Valeurs R√©elles")
ax.set_ylabel("Valeurs Pr√©dites")
ax.set_title("Valeurs R√©elles vs Pr√©dites (Ridge)")
ax.legend()
st.pyplot(fig)

# Interpr√©tation
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üìä Le graphique montre une forte corr√©lation entre les valeurs r√©elles et pr√©dites par le mod√®le Ridge. 
    Comme pour Lasso, la plupart des points sont proches de la ligne de r√©f√©rence, ce qui indique que le mod√®le fait des pr√©dictions pr√©cises.
</p>
""", unsafe_allow_html=True)

# ============================
# Section 5 : Pr√©diction avec de Nouvelles Donn√©es
# ============================
st.header("üîÆ Pr√©diction avec de Nouvelles Donn√©es")

# Exemple de nouvelles donn√©es
new_data = {
    'totalproductslisted': [150],  
    'totalbought': [75],           
    'totalwished': [50],           
    'totalproductsliked': [100]    
}

new_data = pd.DataFrame(new_data)
st.write("**Nouvelles Donn√©es :**")
st.write(new_data)
# Conversion en DataFrame
new_df = pd.DataFrame(new_data)

# Standardisation des nouvelles donn√©es
new_scaled = scaler.transform(new_df)

# Pr√©diction avec Lasso
new_pred_lasso = lasso.predict(new_scaled)
st.write(f"**Pr√©diction Lasso :** {new_pred_lasso[0]:.2f} produits vendus")

# Interpr√©tation
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üéØ Le mod√®le de r√©gression Lasso pr√©dit qu'avec les caract√©ristiques fournies (produits list√©s, achet√©s, souhait√©s et aim√©s), environ 230 produits seront vendus.
</p>
""", unsafe_allow_html=True)

# Pr√©diction avec Ridge
new_pred_ridge = ridge.predict(new_scaled)
st.write(f"**Pr√©diction Ridge :** {new_pred_ridge[0]:.2f} produits vendus")

# Interpr√©tation
st.markdown("""
<p style="text-align: justify; background-color: #e8f4f8; padding: 10px; border-radius: 10px; color: #333;">
    üéØ Le mod√®le de r√©gression Ridge pr√©dit qu'avec les caract√©ristiques fournies (produits list√©s, achet√©s, souhait√©s et aim√©s), environ 168 produits seront vendus.
</p>
""", unsafe_allow_html=True)